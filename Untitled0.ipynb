{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONDtKfI7QFbBCwZA/GLjI6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ulvem/Sail-Into-the-Wind/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading Data"
      ],
      "metadata": {
        "id": "BfdHkGzcOSE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7EzsG16ICoT",
        "outputId": "b43f3752-7fe6-4ff3-8a87-dd0539767695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Yr  Mo  Dy    RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
            "0  61   1   1  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
            "1  61   1   2  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
            "2  61   1   3  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
            "3  61   1   4  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
            "4  61   1   5  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
            "\n",
            "     CLO    BEL    MAL  \n",
            "0  12.58  18.50  15.04  \n",
            "1   9.67  17.54  13.83  \n",
            "2   7.67  12.75  12.71  \n",
            "3   5.88   5.46  10.88  \n",
            "4  10.34  12.92  11.83  \n",
            "    Yr_Mo_Dy    RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
            "0 2061-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
            "1 2061-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
            "2 2061-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
            "3 2061-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
            "4 2061-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
            "\n",
            "     CLO    BEL    MAL  \n",
            "0  12.58  18.50  15.04  \n",
            "1   9.67  17.54  13.83  \n",
            "2   7.67  12.75  12.71  \n",
            "3   5.88   5.46  10.88  \n",
            "4  10.34  12.92  11.83  \n",
            "DataFrame shape: (6574, 13)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv('wind.csv')\n",
        "\n",
        "# Print the first few rows of the DataFrame to inspect the data\n",
        "print(data.head())\n",
        "\n",
        "# Combine the 'Yr', 'Mo', and 'Dy' columns into a single datetime column\n",
        "data['Yr_Mo_Dy'] = pd.to_datetime(data[['Yr', 'Mo', 'Dy']].astype(str).agg('-'.join, axis=1), format='%y-%m-%d')\n",
        "\n",
        "# Drop the original 'Yr', 'Mo', and 'Dy' columns\n",
        "data.drop(columns=['Yr', 'Mo', 'Dy'], inplace=True)\n",
        "\n",
        "# Reorder the columns to have 'Yr_Mo_Dy' as the first column\n",
        "cols = ['Yr_Mo_Dy'] + [col for col in data if col != 'Yr_Mo_Dy']\n",
        "data = data[cols]\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the changes\n",
        "print(data.head())\n",
        "\n",
        "# Verify the shape of the DataFrame\n",
        "print(\"DataFrame shape:\", data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixing Data\n",
        "Year 2061? Surely, we don't possess data from the future. Construct a function to correct this anomaly and implement it. If the date's year exceeds 1989, it indicates a data error. Check how often it happens. In such instances, subtract 100 from the year to rectify the error.\n",
        "\n",
        "All dates are between 1961 and 1978.\n",
        "\n"
      ],
      "metadata": {
        "id": "4p_QM0_AOiLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def correct_year_anomaly(df):\n",
        "    # Count the number of anomalies\n",
        "    anomaly_count = (df['Yr_Mo_Dy'].dt.year > 1989).sum()\n",
        "\n",
        "    # Correct the year anomaly\n",
        "    df.loc[df['Yr_Mo_Dy'].dt.year > 1989, 'Yr_Mo_Dy'] = df['Yr_Mo_Dy'] - pd.DateOffset(years=100)\n",
        "\n",
        "    return df, anomaly_count\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv('wind.csv')\n",
        "\n",
        "# Combine the 'Yr', 'Mo', and 'Dy' columns into a single datetime column\n",
        "data['Yr_Mo_Dy'] = pd.to_datetime(data[['Yr', 'Mo', 'Dy']].astype(str).agg('-'.join, axis=1), format='%y-%m-%d')\n",
        "\n",
        "# Drop the original 'Yr', 'Mo', and 'Dy' columns\n",
        "data.drop(columns=['Yr', 'Mo', 'Dy'], inplace=True)\n",
        "\n",
        "# Reorder the columns to have 'Yr_Mo_Dy' as the first column\n",
        "cols = ['Yr_Mo_Dy'] + [col for col in data if col != 'Yr_Mo_Dy']\n",
        "data = data[cols]\n",
        "\n",
        "# Correct the year anomaly and get the count of anomalies\n",
        "data, anomaly_count = correct_year_anomaly(data)\n",
        "\n",
        "# Print the corrected DataFrame and the count of anomalies\n",
        "print(data.head())\n",
        "print(f\"Number of anomalies corrected: {anomaly_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S0t6VhROHr4",
        "outputId": "a20862b0-a5c3-4a07-938e-72090eadc164"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Yr_Mo_Dy    RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
            "0 1961-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
            "1 1961-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
            "2 1961-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
            "3 1961-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
            "4 1961-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
            "\n",
            "     CLO    BEL    MAL  \n",
            "0  12.58  18.50  15.04  \n",
            "1   9.67  17.54  13.83  \n",
            "2   7.67  12.75  12.71  \n",
            "3   5.88   5.46  10.88  \n",
            "4  10.34  12.92  11.83  \n",
            "Number of anomalies corrected: 2922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Index\n",
        "Set the corrected dates as indexes. Pay attention to the data type, it should be datetime64!\n",
        "\n",
        "Date column type is transformed to datetime64.\n",
        "\n",
        "Date column is set as the index of DataFrame.\n",
        "\n",
        "The result should look like this:\n",
        "\n",
        "RPT\tVAL\tROS\n",
        "Yr_Mo_Dy\n",
        "1961-01-01\t15.04\t14.96\t13.17\n",
        "1961-01-02\t14.71\tNaN\t10.83\n",
        "1961-01-03\t18.50\t16.88\t12.33\n",
        "1961-01-04\t10.58\t6.63\t11.75\n",
        "1961-01-05\t13.33\t13.25\t11.42\n"
      ],
      "metadata": {
        "id": "gz0RUWLYO14P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Correct the Year Anomaly\n",
        "First, we'll correct the year anomaly as we did previously."
      ],
      "metadata": {
        "id": "7lUeaDnUPaJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def correct_year_anomaly(df):\n",
        "    # Count the number of anomalies\n",
        "    anomaly_count = (df['Yr_Mo_Dy'].dt.year > 1989).sum()\n",
        "\n",
        "    # Correct the year anomaly\n",
        "    df.loc[df['Yr_Mo_Dy'].dt.year > 1989, 'Yr_Mo_Dy'] = df['Yr_Mo_Dy'] - pd.DateOffset(years=100)\n",
        "\n",
        "    return df, anomaly_count\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv('wind.csv')\n",
        "\n",
        "# Combine the 'Yr', 'Mo', and 'Dy' columns into a single datetime column\n",
        "data['Yr_Mo_Dy'] = pd.to_datetime(data[['Yr', 'Mo', 'Dy']].astype(str).agg('-'.join, axis=1), format='%y-%m-%d')\n",
        "\n",
        "# Drop the original 'Yr', 'Mo', and 'Dy' columns\n",
        "data.drop(columns=['Yr', 'Mo', 'Dy'], inplace=True)\n",
        "\n",
        "# Reorder the columns to have 'Yr_Mo_Dy' as the first column\n",
        "cols = ['Yr_Mo_Dy'] + [col for col in data if col != 'Yr_Mo_Dy']\n",
        "data = data[cols]\n",
        "\n",
        "# Correct the year anomaly and get the count of anomalies\n",
        "data, anomaly_count = correct_year_anomaly(data)\n",
        "\n",
        "# Print the corrected DataFrame and the count of anomalies\n",
        "print(data.head())\n",
        "print(f\"Number of anomalies corrected: {anomaly_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryHPkPpoPFIT",
        "outputId": "cff8603b-bcde-4960-e866-04d8374f935c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Yr_Mo_Dy    RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
            "0 1961-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
            "1 1961-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
            "2 1961-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
            "3 1961-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
            "4 1961-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
            "\n",
            "     CLO    BEL    MAL  \n",
            "0  12.58  18.50  15.04  \n",
            "1   9.67  17.54  13.83  \n",
            "2   7.67  12.75  12.71  \n",
            "3   5.88   5.46  10.88  \n",
            "4  10.34  12.92  11.83  \n",
            "Number of anomalies corrected: 2922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Set the Corrected Dates as Index\n",
        "\n",
        "Now, we'll set the corrected dates as the index of the DataFrame and ensure the data type is datetime64."
      ],
      "metadata": {
        "id": "wojeKLg8Pc9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the 'Yr_Mo_Dy' column as the index\n",
        "data.set_index('Yr_Mo_Dy', inplace=True)\n",
        "\n",
        "# Ensure the index is of type datetime64\n",
        "data.index = pd.to_datetime(data.index)\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the changes\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHLfDlgmPRKY",
        "outputId": "9b8e489f-c129-48a4-9759-cb0ae5811345"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
            "Yr_Mo_Dy                                                                   \n",
            "1961-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
            "1961-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
            "1961-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
            "1961-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
            "1961-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
            "\n",
            "              CLO    BEL    MAL  \n",
            "Yr_Mo_Dy                         \n",
            "1961-01-01  12.58  18.50  15.04  \n",
            "1961-01-02   9.67  17.54  13.83  \n",
            "1961-01-03   7.67  12.75  12.71  \n",
            "1961-01-04   5.88   5.46  10.88  \n",
            "1961-01-05  10.34  12.92  11.83  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dealing with Missing Values\n",
        "Compute how many values are missing for each location over the entire period.\n",
        "\n",
        "Number of missing values for each location:\n",
        "\n",
        "RPT 6\n",
        "VAL 3\n",
        "ROS 2\n",
        "KIL 5\n",
        "SHA 2\n",
        "BIR 0\n",
        "DUB 3\n",
        "CLA 2\n",
        "MUL 3\n",
        "CLO 1\n",
        "BEL 0\n",
        "MAL 4"
      ],
      "metadata": {
        "id": "FCzuX8kTPuRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Load the Data and Correct the Year Anomaly\n",
        "\n",
        "First, we'll load the data and correct the year anomaly as we did previously."
      ],
      "metadata": {
        "id": "LyBRvtajP235"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def correct_year_anomaly(df):\n",
        "    # Count the number of anomalies\n",
        "    anomaly_count = (df['Yr_Mo_Dy'].dt.year > 1989).sum()\n",
        "\n",
        "    # Correct the year anomaly\n",
        "    df.loc[df['Yr_Mo_Dy'].dt.year > 1989, 'Yr_Mo_Dy'] = df['Yr_Mo_Dy'] - pd.DateOffset(years=100)\n",
        "\n",
        "    return df, anomaly_count\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv('wind.csv')\n",
        "\n",
        "# Combine the 'Yr', 'Mo', and 'Dy' columns into a single datetime column\n",
        "data['Yr_Mo_Dy'] = pd.to_datetime(data[['Yr', 'Mo', 'Dy']].astype(str).agg('-'.join, axis=1), format='%y-%m-%d')\n",
        "\n",
        "# Drop the original 'Yr', 'Mo', and 'Dy' columns\n",
        "data.drop(columns=['Yr', 'Mo', 'Dy'], inplace=True)\n",
        "\n",
        "# Reorder the columns to have 'Yr_Mo_Dy' as the first column\n",
        "cols = ['Yr_Mo_Dy'] + [col for col in data if col != 'Yr_Mo_Dy']\n",
        "data = data[cols]\n",
        "\n",
        "# Correct the year anomaly and get the count of anomalies\n",
        "data, anomaly_count = correct_year_anomaly(data)\n",
        "\n",
        "# Set the 'Yr_Mo_Dy' column as the index\n",
        "data.set_index('Yr_Mo_Dy', inplace=True)\n",
        "\n",
        "# Ensure the index is of type datetime64\n",
        "data.index = pd.to_datetime(data.index)\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the changes\n",
        "print(data.head())\n",
        "print(f\"Number of anomalies corrected: {anomaly_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BILVd5SAPvn5",
        "outputId": "56e09b6a-a708-4cc8-96f5-eefe5f8c7fee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
            "Yr_Mo_Dy                                                                   \n",
            "1961-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
            "1961-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
            "1961-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
            "1961-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
            "1961-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
            "\n",
            "              CLO    BEL    MAL  \n",
            "Yr_Mo_Dy                         \n",
            "1961-01-01  12.58  18.50  15.04  \n",
            "1961-01-02   9.67  17.54  13.83  \n",
            "1961-01-03   7.67  12.75  12.71  \n",
            "1961-01-04   5.88   5.46  10.88  \n",
            "1961-01-05  10.34  12.92  11.83  \n",
            "Number of anomalies corrected: 2922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Compute the Number of Missing Values for Each Location\n",
        "\n",
        "Now, we'll compute the number of missing values for each location."
      ],
      "metadata": {
        "id": "skQIfSgBP966"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the number of missing values for each location\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# Print the number of missing values for each location\n",
        "print(\"Number of missing values for each location:\\n\", missing_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPKElgZeQEc1",
        "outputId": "9b64b61c-7404-43a9-e0c5-ab21e9d318c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values for each location:\n",
            " RPT    6\n",
            "VAL    3\n",
            "ROS    2\n",
            "KIL    5\n",
            "SHA    2\n",
            "BIR    0\n",
            "DUB    3\n",
            "CLA    2\n",
            "MUL    3\n",
            "CLO    1\n",
            "BEL    0\n",
            "MAL    4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Average Windspeed\n",
        "\n",
        "Compute the average wind speed across all locations and for the entire dataset (in other words, from every row simultaneously). Round off the final figure to two decimal places.\n",
        "\n",
        "The expected result is around: 10.23\n",
        "\n"
      ],
      "metadata": {
        "id": "vAopJ7S8QQOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Calculate the Average Wind Speed\n",
        "\n",
        "Now, we'll calculate the average wind speed across all locations and for the entire dataset."
      ],
      "metadata": {
        "id": "u_wulzQOQy-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average wind speed across all locations and for the entire dataset\n",
        "average_wind_speed = data.mean().mean()\n",
        "\n",
        "# Round off the final figure to two decimal places\n",
        "average_wind_speed = round(average_wind_speed, 2)\n",
        "\n",
        "# Print the average wind speed\n",
        "print(\"Average wind speed across all locations and for the entire dataset:\", average_wind_speed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NigQB57AQcUw",
        "outputId": "e5404603-b4f9-46d4-929c-a22b5ce18c91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average wind speed across all locations and for the entire dataset: 10.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Basic Descriptive Statistics\n",
        "Construct a pd.DataFrame() named wind_stats and determine the minimum, maximum, average wind speeds, and standard deviations of the wind speeds for each location across all days.\n",
        "\n",
        "The expected result looks like this:\n",
        "\n",
        "RPT\tVAL\tROS\n",
        "count\t6568.000000\t6571.000000\t6572.000000\n",
        "mean\t12.362987\t10.644314\t11.660526\n",
        "std\t5.618413\t5.267356\t5.008450\n",
        "min\t0.670000\t0.210000\t1.500000\n",
        "50%\t11.710000\t10.170000\t10.920000\n",
        "max\t35.800000\t33.370000\t33.840000\n"
      ],
      "metadata": {
        "id": "c7ibkGmYRBwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate descriptive statistics\n",
        "wind_stats = data.describe().T\n",
        "\n",
        "# Print the descriptive statistics\n",
        "print(\"Descriptive statistics for wind speeds:\\n\", wind_stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWEzlllnRMuF",
        "outputId": "4f1e39e2-ce98-4603-83ca-f550d2283798"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptive statistics for wind speeds:\n",
            "       count       mean       std   min    25%    50%    75%    max\n",
            "RPT  6568.0  12.362987  5.618413  0.67   8.12  11.71  15.92  35.80\n",
            "VAL  6571.0  10.644314  5.267356  0.21   6.67  10.17  14.04  33.37\n",
            "ROS  6572.0  11.660526  5.008450  1.50   8.00  10.92  14.67  33.84\n",
            "KIL  6569.0   6.306468  3.605811  0.00   3.58   5.75   8.42  28.46\n",
            "SHA  6572.0  10.455834  4.936125  0.13   6.75   9.96  13.54  37.54\n",
            "BIR  6574.0   7.092254  3.968683  0.00   4.00   6.83   9.67  26.16\n",
            "DUB  6571.0   9.797343  4.977555  0.00   6.00   9.21  12.96  30.37\n",
            "CLA  6572.0   8.495053  4.499449  0.00   5.09   8.08  11.42  31.08\n",
            "MUL  6571.0   8.493590  4.166872  0.00   5.37   8.17  11.19  25.88\n",
            "CLO  6573.0   8.707332  4.503954  0.04   5.33   8.29  11.63  28.21\n",
            "BEL  6574.0  13.121007  5.835037  0.13   8.71  12.50  16.88  42.38\n",
            "MAL  6570.0  15.599079  6.699794  0.67  10.71  15.00  19.83  42.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daily Mean\n",
        "Construct a pd.DataFrame() named wind_stats_daily and compute the minimum, maximum, average wind speed, and standard deviations of the wind speeds across all locations for each day separately.\n",
        "\n",
        "The resulting table should look like this:\n",
        "\n",
        "min\tmax\tmean\tstd\n",
        "Yr_Mo_Dy\n",
        "1961-01-01\t9.29\t18.50\t13.018182\t2.808875\n",
        "1961-01-02\t6.50\t17.54\t11.336364\t3.188994\n",
        "1961-01-03\t6.17\t18.50\t11.641818\t3.681912\n",
        "1961-01-04\t1.79\t11.75\t6.619167\t3.198126\n",
        "1961-01-05\t6.17\t13.33\t10.630000\t2.445356\n"
      ],
      "metadata": {
        "id": "l0642HGbR8vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate daily descriptive statistics\n",
        "wind_stats_daily = data.agg(['min', 'max', 'mean', 'std'], axis=1)\n",
        "\n",
        "# Print the daily descriptive statistics\n",
        "print(\"Daily descriptive statistics for wind speeds:\\n\", wind_stats_daily.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbAnvvsDSF_U",
        "outputId": "e7e099a0-a250-49fa-a9d2-33d0b0ab6565"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily descriptive statistics for wind speeds:\n",
            "              min    max       mean       std\n",
            "Yr_Mo_Dy                                    \n",
            "1961-01-01  9.29  18.50  13.018182  2.808875\n",
            "1961-01-02  6.50  17.54  11.336364  3.188994\n",
            "1961-01-03  6.17  18.50  11.641818  3.681912\n",
            "1961-01-04  1.79  11.75   6.619167  3.198126\n",
            "1961-01-05  6.17  13.33  10.630000  2.445356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average Wind Speed for January\n",
        "\n",
        "Determine the average wind speed for each location during the month of January.\n",
        "\n",
        "The result should be the following:\n",
        "\n",
        "RPT\t14.847325\n",
        "VAL\t12.914560\n",
        "ROS\t13.299624\n",
        "KIL\t7.199498\n",
        "SHA\t11.667734\n",
        "BIR\t8.054839\n",
        "DUB\t11.819355\n",
        "CLA\t9.512047\n",
        "MUL\t9.543208\n",
        "CLO\t10.053566\n",
        "BEL\t14.550520\n",
        "MAL\t18.028763\n"
      ],
      "metadata": {
        "id": "UE5JPRH9S31C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Filter Data for January\n",
        "\n"
      ],
      "metadata": {
        "id": "iWwZjRIyTVk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for January\n",
        "january_data = data[data.index.month == 1]\n",
        "\n",
        "# Print the first few rows of the January data to verify the changes\n",
        "print(january_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUJh5DjHTFQY",
        "outputId": "79374750-a911-439f-966a-0a06826d0c50"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
            "Yr_Mo_Dy                                                                   \n",
            "1961-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
            "1961-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
            "1961-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
            "1961-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
            "1961-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
            "\n",
            "              CLO    BEL    MAL  \n",
            "Yr_Mo_Dy                         \n",
            "1961-01-01  12.58  18.50  15.04  \n",
            "1961-01-02   9.67  17.54  13.83  \n",
            "1961-01-03   7.67  12.75  12.71  \n",
            "1961-01-04   5.88   5.46  10.88  \n",
            "1961-01-05  10.34  12.92  11.83  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Calculate the Average Wind Speed for Each Location in January"
      ],
      "metadata": {
        "id": "cXgbN_GgTh9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average wind speed for each location in January\n",
        "average_wind_speed_january = january_data.mean()\n",
        "\n",
        "# Print the average wind speed for each location in January\n",
        "print(\"Average wind speed for each location in January:\\n\", average_wind_speed_january)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWIWXLMPTMD_",
        "outputId": "dcd39ac6-3af0-4e22-b7b6-ec995167e072"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average wind speed for each location in January:\n",
            " RPT    14.847325\n",
            "VAL    12.914560\n",
            "ROS    13.299624\n",
            "KIL     7.199498\n",
            "SHA    11.667734\n",
            "BIR     8.054839\n",
            "DUB    11.819355\n",
            "CLA     9.512047\n",
            "MUL     9.543208\n",
            "CLO    10.053566\n",
            "BEL    14.550520\n",
            "MAL    18.028763\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Yearly Statistics\n",
        "Compute the annual average wind speed for each location.\n",
        "\n",
        "The result is the following:\n",
        "\n",
        "RPT\tVAL\tROS\n",
        "Yr_Mo_Dy\n",
        "1961\t12.299583\t10.351796\t11.362369\n",
        "1962\t12.246923\t10.110438\t11.732712\n",
        "1963\t12.813452\t10.836986\t12.541151\n",
        "1964\t12.363661\t10.920164\t12.104372\n",
        "1965\t12.451370\t11.075534\t11.848767\n",
        "1966\t13.461973\t11.557205\t12.020630\n"
      ],
      "metadata": {
        "id": "2SAV7JG5Tx0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def correct_year_anomaly(df):\n",
        "    # Count the number of anomalies\n",
        "    anomaly_count = (df['Yr_Mo_Dy'].dt.year > 1989).sum()\n",
        "\n",
        "    # Correct the year anomaly\n",
        "    df.loc[df['Yr_Mo_Dy'].dt.year > 1989, 'Yr_Mo_Dy'] = df['Yr_Mo_Dy'] - pd.DateOffset(years=100)\n",
        "\n",
        "    return df, anomaly_count\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv('wind.csv')\n",
        "\n",
        "# Combine the 'Yr', 'Mo', and 'Dy' columns into a single datetime column\n",
        "data['Yr_Mo_Dy'] = pd.to_datetime(data[['Yr', 'Mo', 'Dy']].astype(str).agg('-'.join, axis=1), format='%y-%m-%d')\n",
        "\n",
        "# Drop the original 'Yr', 'Mo', and 'Dy' columns\n",
        "data.drop(columns=['Yr', 'Mo', 'Dy'], inplace=True)\n",
        "\n",
        "# Reorder the columns to have 'Yr_Mo_Dy' as the first column\n",
        "cols = ['Yr_Mo_Dy'] + [col for col in data if col != 'Yr_Mo_Dy']\n",
        "data = data[cols]\n",
        "\n",
        "# Correct the year anomaly and get the count of anomalies\n",
        "data, anomaly_count = correct_year_anomaly(data)\n",
        "\n",
        "# Set the 'Yr_Mo_Dy' column as the index\n",
        "data.set_index('Yr_Mo_Dy', inplace=True)\n",
        "\n",
        "# Ensure the index is of type datetime64\n",
        "data.index = pd.to_datetime(data.index)\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the changes\n",
        "print(data.head())\n",
        "print(f\"Number of anomalies corrected: {anomaly_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvLXz_rPUHv8",
        "outputId": "563bef5f-4873-4fd1-93d2-82ae8c1658ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
            "Yr_Mo_Dy                                                                   \n",
            "1961-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
            "1961-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
            "1961-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
            "1961-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
            "1961-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
            "\n",
            "              CLO    BEL    MAL  \n",
            "Yr_Mo_Dy                         \n",
            "1961-01-01  12.58  18.50  15.04  \n",
            "1961-01-02   9.67  17.54  13.83  \n",
            "1961-01-03   7.67  12.75  12.71  \n",
            "1961-01-04   5.88   5.46  10.88  \n",
            "1961-01-05  10.34  12.92  11.83  \n",
            "Number of anomalies corrected: 2922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by year and calculate the mean for each location\n",
        "annual_avg_wind_speed = data.resample('Y').mean()\n",
        "\n",
        "# Print the annual average wind speed\n",
        "print(\"Annual average wind speed for each location:\\n\", annual_avg_wind_speed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgxOzYJOT6W3",
        "outputId": "d161b98f-69c7-4e3d-9b9f-48cd68bf8b3a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annual average wind speed for each location:\n",
            "                   RPT        VAL        ROS       KIL        SHA       BIR  \\\n",
            "Yr_Mo_Dy                                                                     \n",
            "1961-12-31  12.299583  10.351796  11.362369  6.958227  10.881763  7.729726   \n",
            "1962-12-31  12.246923  10.110438  11.732712  6.960440  10.657918  7.393068   \n",
            "1963-12-31  12.813452  10.836986  12.541151  7.330055  11.724110  8.434712   \n",
            "1964-12-31  12.363661  10.920164  12.104372  6.787787  11.454481  7.570874   \n",
            "1965-12-31  12.451370  11.075534  11.848767  6.858466  11.024795  7.478110   \n",
            "1966-12-31  13.461973  11.557205  12.020630  7.345726  11.805041  7.793671   \n",
            "1967-12-31  12.737151  10.990986  11.739397  7.143425  11.630740  7.368164   \n",
            "1968-12-31  11.835628  10.468197  11.409754  6.477678  10.760765  6.067322   \n",
            "1969-12-31  11.166356   9.723699  10.902000  5.767973   9.873918  6.189973   \n",
            "1970-12-31  12.600329  10.726932  11.730247  6.217178  10.567370  7.609452   \n",
            "1971-12-31  11.273123   9.095178  11.088329  5.241507   9.440329  6.097151   \n",
            "1972-12-31  12.463962  10.561311  12.058333  5.929699   9.430410  6.358825   \n",
            "1973-12-31  11.828466  10.680493  10.680493  5.547863   9.640877  6.548740   \n",
            "1974-12-31  13.643096  11.811781  12.336356  6.427041  11.110986  6.809781   \n",
            "1975-12-31  12.008575  10.293836  11.564712  5.269096   9.190082  5.668521   \n",
            "1976-12-31  11.737842  10.203115  10.761230  5.109426   8.846339  6.311038   \n",
            "1977-12-31  13.099616  11.144493  12.627836  6.073945  10.003836  8.586438   \n",
            "1978-12-31  12.504356  11.044274  11.380000  6.082356  10.167233  7.650658   \n",
            "\n",
            "                  DUB        CLA       MUL        CLO        BEL        MAL  \n",
            "Yr_Mo_Dy                                                                     \n",
            "1961-12-31   9.733923   8.858788  8.647652   9.835577  13.502795  13.680773  \n",
            "1962-12-31  11.020712   8.793753  8.316822   9.676247  12.930685  14.323956  \n",
            "1963-12-31  11.075699  10.336548  8.903589  10.224438  13.638877  14.999014  \n",
            "1964-12-31  10.259153   9.467350  7.789016  10.207951  13.740546  14.910301  \n",
            "1965-12-31  10.618712   8.879918  7.907425   9.918082  12.964247  15.591644  \n",
            "1966-12-31  10.579808   8.835096  8.514438   9.768959  14.265836  16.307260  \n",
            "1967-12-31  10.652027   9.325616  8.645014   9.547425  14.774548  17.135945  \n",
            "1968-12-31   8.859180   8.255519  7.224945   7.832978  12.808634  15.017486  \n",
            "1969-12-31   8.564493   7.711397  7.924521   7.754384  12.621233  15.762904  \n",
            "1970-12-31   9.609890   8.334630  9.297616   8.289808  13.183644  16.456027  \n",
            "1971-12-31   8.385890   6.757315  7.915370   7.229753  12.208932  15.025233  \n",
            "1972-12-31   9.704508   7.680792  8.357295   7.515273  12.727377  15.028716  \n",
            "1973-12-31   8.482110   7.614274  8.245534   7.812411  12.169699  15.441096  \n",
            "1974-12-31  10.084603   9.896986  9.331753   8.736356  13.252959  16.947671  \n",
            "1975-12-31   8.562603   7.843836  8.797945   7.382822  12.631671  15.307863  \n",
            "1976-12-31   9.149126   7.146202  8.883716   7.883087  12.332377  15.471448  \n",
            "1977-12-31  11.523205   8.378384  9.098192   8.821616  13.459068  16.590849  \n",
            "1978-12-31   9.489342   8.800466  9.089753   8.301699  12.967397  16.771370  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-3c2167b18da2>:2: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
            "  annual_avg_wind_speed = data.resample('Y').mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weekly Statistics\n",
        "Reduce the dataset to a weekly frequency for each location, aggregating the data points to represent each week (by getting the mean values).\n",
        "\n",
        "The weekly means should be the following:\n",
        "\n",
        "RPT\tVAL\tROS\n",
        "Yr_Mo_Dy\n",
        "1960-12-26/1961-01-01\t15.040000\t14.960000\t13.170000\n",
        "1961-01-02/1961-01-08\t13.541429\t11.486667\t10.487143\n",
        "1961-01-09/1961-01-15\t12.468571\t8.967143\t11.958571\n",
        "1961-01-16/1961-01-22\t13.204286\t9.862857\t12.982857\n"
      ],
      "metadata": {
        "id": "nE84U6_tUSUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample the data to weekly frequency and calculate the mean for each week\n",
        "weekly_data = data.resample('W').mean()\n",
        "\n",
        "# Print the first few rows of the weekly data to verify the changes\n",
        "print(weekly_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S61NR5dfUhBv",
        "outputId": "82d3f251-f152-4d8d-b896-d45e3009a300"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  RPT        VAL        ROS        KIL        SHA        BIR  \\\n",
            "Yr_Mo_Dy                                                                       \n",
            "1961-01-01  15.040000  14.960000  13.170000   9.290000        NaN   9.870000   \n",
            "1961-01-08  13.541429  11.486667  10.487143   6.417143   9.474286   6.435714   \n",
            "1961-01-15  12.468571   8.967143  11.958571   4.630000   7.351429   5.072857   \n",
            "1961-01-22  13.204286   9.862857  12.982857   6.328571   8.966667   7.417143   \n",
            "1961-01-29  19.880000  16.141429  18.225714  12.720000  17.432857  14.828571   \n",
            "\n",
            "                  DUB        CLA        MUL        CLO        BEL        MAL  \n",
            "Yr_Mo_Dy                                                                      \n",
            "1961-01-01  13.670000  10.250000  10.830000  12.580000  18.500000  15.040000  \n",
            "1961-01-08  11.061429   6.616667   8.434286   8.497143  12.481429  13.238571  \n",
            "1961-01-15   7.535714   6.820000   5.712857   7.571429  11.125714  11.024286  \n",
            "1961-01-22   9.257143   7.875714   7.145714   8.124286   9.821429  11.434286  \n",
            "1961-01-29  15.528571  15.160000  14.480000  15.640000  20.930000  22.530000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More Weekly Statistics\n",
        "Compute the minimum, maximum, average wind speeds, and standard deviations of the wind speeds across all locations for each week, starting from the week of January 2, 1961, covering the initial 52 weeks.\n",
        "\n",
        "The result is the following:\n",
        "\n",
        "RPT\t\t\t\tVAL\n",
        "min\tmax\tmean\tstd\tmin\tmax\tmean\tstd\n",
        "Yr_Mo_Dy\n",
        "1961-01-08\t10.58\t18.50\t13.541429\t2.631321\t6.63\t16.88\t11.486667\t3.949525\n",
        "1961-01-15\t9.04\t19.75\t12.468571\t3.555392\t3.54\t12.08\t8.967143\t3.148945\n",
        "1961-01-22\t4.92\t19.83\t13.204286\t5.337402\t3.42\t14.37\t9.862857\t3.837785\n",
        "1961-01-29\t13.62\t25.04\t19.880000\t4.619061\t9.96\t23.91\t16.141429\t5.170224\n",
        "1961-02-05\t10.58\t24.21\t16.827143\t5.251408\t9.46\t24.21\t15.460000\t5.187395\n"
      ],
      "metadata": {
        "id": "dVz9XEYMUoJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample the data to weekly frequency and calculate the mean for each week\n",
        "weekly_data = data.resample('W').mean()\n",
        "\n",
        "# Print the first few rows of the weekly data to verify the changes\n",
        "print(weekly_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUnqQ-24U0wo",
        "outputId": "18b74f87-33d9-4cae-ea8d-4b8857e228be"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  RPT        VAL        ROS        KIL        SHA        BIR  \\\n",
            "Yr_Mo_Dy                                                                       \n",
            "1961-01-01  15.040000  14.960000  13.170000   9.290000        NaN   9.870000   \n",
            "1961-01-08  13.541429  11.486667  10.487143   6.417143   9.474286   6.435714   \n",
            "1961-01-15  12.468571   8.967143  11.958571   4.630000   7.351429   5.072857   \n",
            "1961-01-22  13.204286   9.862857  12.982857   6.328571   8.966667   7.417143   \n",
            "1961-01-29  19.880000  16.141429  18.225714  12.720000  17.432857  14.828571   \n",
            "\n",
            "                  DUB        CLA        MUL        CLO        BEL        MAL  \n",
            "Yr_Mo_Dy                                                                      \n",
            "1961-01-01  13.670000  10.250000  10.830000  12.580000  18.500000  15.040000  \n",
            "1961-01-08  11.061429   6.616667   8.434286   8.497143  12.481429  13.238571  \n",
            "1961-01-15   7.535714   6.820000   5.712857   7.571429  11.125714  11.024286  \n",
            "1961-01-22   9.257143   7.875714   7.145714   8.124286   9.821429  11.434286  \n",
            "1961-01-29  15.528571  15.160000  14.480000  15.640000  20.930000  22.530000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the data to start from January 2, 1961\n",
        "weekly_data = weekly_data.loc['1961-01-02':'1962-01-01']\n",
        "\n",
        "# Calculate the descriptive statistics for each week\n",
        "weekly_stats = weekly_data.agg(['min', 'max', 'mean', 'std'], axis=1)\n",
        "\n",
        "# Print the weekly descriptive statistics\n",
        "print(\"Weekly descriptive statistics for wind speeds:\\n\", weekly_stats.head(52))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8SF9SmvU2jZ",
        "outputId": "e046702f-c450-47a5-a20a-62e101cbf222"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weekly descriptive statistics for wind speeds:\n",
            "                   min        max       mean       std\n",
            "Yr_Mo_Dy                                             \n",
            "1961-01-08   6.417143  13.541429   9.847659  2.601705\n",
            "1961-01-15   4.630000  12.468571   8.353214  2.719649\n",
            "1961-01-22   6.328571  13.204286   9.368413  2.224531\n",
            "1961-01-29  12.720000  22.530000  16.958095  2.915635\n",
            "1961-02-05   8.247143  16.827143  11.800357  2.807310\n",
            "1961-02-12  10.774286  21.832857  15.891548  3.147412\n",
            "1961-02-19   9.542857  21.167143  13.726825  3.105819\n",
            "1961-02-26   8.524286  16.304286  12.604286  2.364323\n",
            "1961-03-05   7.834286  17.842857  11.766766  2.535336\n",
            "1961-03-12   6.881429  16.701429  10.612579  2.746233\n",
            "1961-03-19   7.084286  19.350000  11.756310  3.320318\n",
            "1961-03-26   6.648571  18.134286  10.462857  3.071975\n",
            "1961-04-02   7.300000  13.900000  10.268433  1.883742\n",
            "1961-04-09   5.958571  13.607143   9.412381  2.399840\n",
            "1961-04-16   4.947143   9.482857   6.845595  1.803831\n",
            "1961-04-23   7.768571  13.620000  10.146667  1.895943\n",
            "1961-04-30   4.801429  10.117143   7.445000  1.864130\n",
            "1961-05-07   9.952857  17.548571  13.164048  2.223149\n",
            "1961-05-14   5.295714  10.421429   8.059802  1.491250\n",
            "1961-05-21   4.258571  12.042857   7.470258  2.327906\n",
            "1961-05-28   3.748333  11.697143   7.177956  2.370473\n",
            "1961-06-04   6.310000  13.597143   9.244643  2.167131\n",
            "1961-06-11   5.214286  12.250000   8.459048  2.136900\n",
            "1961-06-18   6.520000  15.351429  10.173810  2.676791\n",
            "1961-06-25   5.478571  17.410000  10.066548  3.494271\n",
            "1961-07-02   6.507143  14.535714   9.528810  2.311594\n",
            "1961-07-09   7.220000  15.987143  10.580099  2.505843\n",
            "1961-07-16   8.412857  16.680000  11.666190  2.483875\n",
            "1961-07-23   2.715714   8.415714   5.350952  1.726225\n",
            "1961-07-30   5.727143  13.761429   9.431071  2.279097\n",
            "1961-08-06   6.238571  13.760000   9.446786  2.099734\n",
            "1961-08-13   5.078571  10.934286   8.199206  1.855421\n",
            "1961-08-20   8.600000  16.626667  12.668413  2.466378\n",
            "1961-08-27   7.108571  16.485714  12.061786  2.649263\n",
            "1961-09-03   5.642857  13.664286   8.437381  2.300787\n",
            "1961-09-10   5.685714  11.034286   8.186786  1.866173\n",
            "1961-09-17  10.442857  19.878571  14.510833  3.058931\n",
            "1961-09-24   4.851667  11.018571   7.247937  1.958569\n",
            "1961-10-01   8.370000  16.208571  11.771091  2.750518\n",
            "1961-10-08   5.262857  11.410000   8.034167  2.148981\n",
            "1961-10-15   6.578571  15.260000   9.828115  2.680505\n",
            "1961-10-22  10.721429  23.641429  15.479643  3.509702\n",
            "1961-10-29   8.408571  18.404286  12.688631  3.139748\n",
            "1961-11-05   7.541429  19.195714  11.612857  3.253959\n",
            "1961-11-12   4.220000  10.858571   7.487262  2.516385\n",
            "1961-11-19   4.501429  16.988571   7.647024  3.534858\n",
            "1961-11-26   4.970000  12.732857   8.755516  2.472631\n",
            "1961-12-03   6.245714  14.725714   9.754762  2.724343\n",
            "1961-12-10   8.624286  17.362857  13.145357  2.904971\n",
            "1961-12-17   8.697143  15.112857  12.703095  2.110713\n",
            "1961-12-24   5.517143  15.757143   9.315714  3.174787\n",
            "1961-12-31   5.372857  15.804286   9.562381  3.288602\n"
          ]
        }
      ]
    }
  ]
}